{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13886014-3eee-496d-9843-905311e80b41",
   "metadata": {},
   "source": [
    "# **SeqOne** - *Analyse et Machine Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8253cad-d745-4ad5-8e0a-3c303f13148d",
   "metadata": {},
   "source": [
    "Sommaire :\n",
    "1. Analyse exploratoire\n",
    "2. Pre-processing\n",
    "3. Machine Learning\n",
    "4. Propositions d'améliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b917f1-ed5f-484e-8ab9-347b17a54aba",
   "metadata": {},
   "source": [
    "## 1. Analyse exploratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979daf8-0735-4f46-998e-aa122976824e",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1cd12-62df-4e1f-a4cf-495186695bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "    # machine learning libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "    # loading the dataset\n",
    "\n",
    "df = pd.read_csv(\"dataframe.tsv\", sep =\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e996b3-5fde-47bb-9c59-c52f7466f8fe",
   "metadata": {},
   "source": [
    "### a) caractéristiques du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e633ec8-aa74-4190-90e1-d5dda0c27e82",
   "metadata": {},
   "source": [
    "#### *- générales*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c961356-696e-43dd-a4b0-ccafd3aee8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensions : {df.shape}.\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b97a48-dd0e-401e-aefb-3b9610220021",
   "metadata": {},
   "source": [
    "___\n",
    "Le jeu de données est constitué de 438 lignes et 40 colonnes, dont 2 colonnes index (build_variant_id et contigName), 1 colonne *target* (class) et 37 colonnes *features*.\n",
    "\n",
    "Les données sont numériques (booléennes, continues ou catégorielles), hormis la colonne d'index 0.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d5571-a983-40ab-b89d-833e0a43fe6a",
   "metadata": {},
   "source": [
    "#### *- statistiques*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157af249-b285-447c-8ea9-c7edbc1b0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_stats=df.describe().transpose()\n",
    "print(numerical_columns_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587870b3-62fd-46e6-9a24-261af9fd40b4",
   "metadata": {},
   "source": [
    "___\n",
    "Observations :\n",
    "+ Aucune variable n’est négative. \n",
    "+ La plupart d’entre elles ne dépassent pas la valeur 1. \n",
    "+ Certaines ne dépassent pas un certain entier, aux alentours de 7 ou 8.\n",
    "+ Rarement, des variables ont un plus grand écart-type qui dépasse la centaine.\n",
    "+ Un nombre non-négligeable de ces variables ont seulement deux valeurs : 0 ou 1, elles sont certainement de type booléen.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc9fe4-68f8-4f88-8847-596a53cb05a1",
   "metadata": {},
   "source": [
    "### b) valeurs manquantes (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cabcec-4807-48ca-9f99-06412f1a4aa6",
   "metadata": {},
   "source": [
    "#### *- colonnes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277415c-c8be-40f9-848c-ef1964328fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = df.isna()\n",
    "for column_name in df_na.columns[3:]:\n",
    "    column = df_na[column_name]\n",
    "    count = int(((column == True).sum()/438)*100)\n",
    "    df_na = df_na.rename(columns={column_name:f\"{column_name} ({count}%)\"})\n",
    "\n",
    "plt.suptitle('Valeurs NaN (en blanc)', fontweight='bold' )\n",
    "sns.heatmap(df_na, xticklabels=True, yticklabels=False, cbar=False, linewidths=0)\n",
    "plt.xticks(rotation = 90, fontsize=7)\n",
    "plt.xlabel(\"Columns (NaN %)\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28405f-66c8-4058-a870-12e2fe6ff34f",
   "metadata": {},
   "source": [
    "___\n",
    "+ Sur la base de la distribution des valeurs manquantes, on peut supposer des relations entre différentes colonnes :\n",
    "    + entre spa et sprf\n",
    "    + EXON et INTRON\n",
    "    + gene_cluster, lof_gene, missense_gene\n",
    "    + peut-être gfq et sft\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb9668-2789-4af1-885e-2a41c07a8d13",
   "metadata": {},
   "source": [
    "#### *- lignes*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9006e-d745-475f-af04-7ffcc58d727e",
   "metadata": {},
   "source": [
    "Un cluster de valeurs manquantes est observé dans Spyder :\n",
    "![https://ibb.co/Kw1zHyR](https://i.ibb.co/6BdJ5sV/lines-missing.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd3016-6926-479d-98ef-6948b1057e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ce cluster est constitué de {df['gene_cluster'].isna().sum()} valeurs manquantes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce35734-993a-4312-9c9c-49568a88d7a8",
   "metadata": {},
   "source": [
    "### c) doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb560abf-e784-456c-b338-f683eef07d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Il y a {df.duplicated().sum()} doublon(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a06050-36d0-4cb7-973c-e4631b6b0310",
   "metadata": {},
   "source": [
    "### d) valeurs égales à zéro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e99a13-fc18-4830-a8eb-08e419a098ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = (df == 0)\n",
    "for column_name in df_zero.columns[3:]:\n",
    "    column = df_zero[column_name]\n",
    "    count = int(((column == True).sum()/438)*100)\n",
    "    df_zero = df_zero.rename(columns={column_name:f\"{column_name} ({count}%)\"})\n",
    "\n",
    "plt.suptitle('Valeurs égale à 0 (en blanc)', fontweight='bold' )\n",
    "sns.heatmap(df_zero, xticklabels=True, yticklabels=False, cbar=False, linewidths=0)\n",
    "plt.suptitle('Valeurs égales à 0 (en blanc)', fontweight='bold' )\n",
    "plt.xticks(rotation = 90, fontsize=7)\n",
    "plt.xlabel(\"Columns (zero values %)\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda55b9b-5dcb-4d79-868c-ff109f6bdf50",
   "metadata": {},
   "source": [
    "___\n",
    "+ De nombreuses valeurs égales à zéro sont observées parmi les différentes colonnes.\n",
    "+ Les colonnes d’index 3, 6, 7, 8, 9, 10, 15, 30, 32, 38 et 39 ont à plus de 90% la valeur zéro\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930fdfc-ca97-4cb1-9a62-60d684dfbd4a",
   "metadata": {},
   "source": [
    "### e) valeurs uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e49fe-17d9-408b-86bf-f755f4991dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in df.columns[2:]:\n",
    "    column = df[column_name]\n",
    "    unique = column.unique()\n",
    "    nunique = column.nunique()\n",
    "    print(f\"\\n{nunique} unique values in '{column_name}':\\n{unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf84c26-69bb-4649-a089-6c9f52d0e7d4",
   "metadata": {},
   "source": [
    "___\n",
    "+ 'stop_retained_variant' n'a qu'une seule valeur unique.\n",
    "+ Parmi les colonnes de type int64, les colonnes 17, 19, 21, 23, 38 et 39 n’ont que deux valeurs. Il semblerait qu’elles soient des variables booléennes.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f228d6-5e35-42b8-8570-844083a7c19c",
   "metadata": {},
   "source": [
    "### f) type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e38e40-0d68-4638-9d86-6ec0077f6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1=pd.Series(df.dtypes)\n",
    "ser2=df.nunique()\n",
    "df_dtypes= pd.concat([ser1, ser2], axis=\"columns\").rename(columns={0:\"dtype\", 1:\"nunique\"})\n",
    "print(df_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1d91e-1b25-4176-b351-ef890272fd37",
   "metadata": {},
   "source": [
    "___\n",
    "On peut en déduire que, malgré le fait que la plupart des variables sont de type float64, elles ont un nombre limité de valeurs possible. Cela signifie probablement que ces données sont davantage catégorielles ou booléennes que continues.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c871a29-ae50-420e-853f-c084eb41e05e",
   "metadata": {},
   "source": [
    "### g) distribution de chaque colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b89677-b8e3-4ae4-8714-9d2f4c764508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution de chaque colonne sous forme de barplot [1/4]\n",
    "# étant donné que la plupart des colonnes sont catégorielles\n",
    "\n",
    "for x in range(2,10):\n",
    "    groupby = df.groupby(df.columns[x])[df.columns[x]].count()\n",
    "    \n",
    "    plt.figure(x)\n",
    "    sns.barplot(x=groupby.index, y=groupby)\n",
    "    plt.ylim(0, 438)\n",
    "    plt.xlabel(\"Unique Values\")\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.suptitle(df.columns[x], fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba3e18-661c-4d84-9ae6-395106c152e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2/4]\n",
    "\n",
    "for x in range(10,20):\n",
    "    groupby = df.groupby(df.columns[x])[df.columns[x]].count()\n",
    "    \n",
    "    plt.figure(x)\n",
    "    sns.barplot(x=groupby.index, y=groupby)\n",
    "    plt.ylim(0, 438)\n",
    "    plt.xlabel(\"Unique Values\")\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.suptitle(df.columns[x], fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32c347-8ec3-4763-b643-d686d773d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3/4]\n",
    "\n",
    "for x in range(20,30):\n",
    "    groupby = df.groupby(df.columns[x])[df.columns[x]].count()\n",
    "    \n",
    "    plt.figure(x)\n",
    "    sns.barplot(x=groupby.index, y=groupby)\n",
    "    plt.ylim(0, 438)\n",
    "    plt.xlabel(\"Unique Values\")\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.suptitle(df.columns[x], fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce863c20-aa4e-4344-802d-6deed3abf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4/4]\n",
    "\n",
    "for x in range(30,len(df.columns)):\n",
    "    groupby = df.groupby(df.columns[x])[df.columns[x]].count()\n",
    "    \n",
    "    plt.figure(x)\n",
    "    sns.barplot(x=groupby.index, y=groupby)\n",
    "    plt.ylim(0, 438)\n",
    "    plt.xlabel(\"Unique Values\")\n",
    "    plt.ylabel(\"Total Count\")\n",
    "    plt.suptitle(df.columns[x], fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9bd5c-d09f-4625-ad8b-cd039c576a5a",
   "metadata": {},
   "source": [
    "___\n",
    "Maintenant que le jeu de données est connu dans ses grandes lignes, on peut passer à l'étape de pre-processing, afin de le rendre exploitable par les algorithmes de machine learning.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84a566-8a1a-4d80-8929-7dc1f62c6504",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148723c3-3abf-4c19-ada0-6d44b9728cd7",
   "metadata": {},
   "source": [
    "### a) Suppression des colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d4cac-2ead-404e-a3c2-5a15640504a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # les index\n",
    "print(f'Index columns:')\n",
    "df_ml = df.drop(columns=['build_variant_id', 'contigName'])\n",
    "print(f'\\tDropped column: build_variant_id.')\n",
    "print(f'\\tDropped column: contigName.')\n",
    "\n",
    "    # les colonnes ayant plus de 50% de NaN\n",
    "print('\\n>50% NaN values columns:')\n",
    "for x in df_ml :\n",
    "        if df_ml[x].isnull().sum() > (len(df. index)/2):\n",
    "            df_ml = df_ml.drop(columns=[x])\n",
    "            print(f'\\tDropped column: {x}.')\n",
    "\n",
    "    # les colonnes uniformes\n",
    "print('\\nUniform columns:')\n",
    "for x in df_ml :\n",
    "        if df_ml[x].nunique()==1:\n",
    "            df_ml=df_ml.drop(columns=[x])\n",
    "            print(f'\\tDropped column: {x}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ed80d-79c6-4f31-b651-02169799e7e4",
   "metadata": {},
   "source": [
    "___\n",
    "Les colonnes qui ont plus de 50% de données manquantes ont été supprimées, ainsi que les colonnes uniformes ou non-numériques.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79872a88-84dd-4a0c-9936-8f77fd13fae9",
   "metadata": {},
   "source": [
    "### b) suppression des lignes inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df70c5-c02b-4fa1-a889-d6eea9eb26a1",
   "metadata": {},
   "source": [
    "___\n",
    "Précédemment, un cluster de lignes avec plusieurs valeurs manquantes a été identifié. Mais elles ne seront pas supprimées car le nombre de lignes du jeu de données est déjà limité.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d047a7-4737-44f1-a4a5-7c38238f894f",
   "metadata": {},
   "source": [
    "### c) traitement des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb727028-acae-40ef-9a1c-0de7d7274a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # colonnes booléennes\n",
    "\n",
    "bool_cols=[]\n",
    "\n",
    "for x in df_ml :\n",
    "        if df_ml[x].nunique() == 2:\n",
    "            for y in df_ml[x].unique():\n",
    "                if y == (0 or 1):\n",
    "                    bool_cols.append(x)\n",
    "\n",
    "df_ml[bool_cols]=df_ml[bool_cols].fillna(0)\n",
    "print('Boolean columns filled with 0:\\n', bool_cols)\n",
    "\n",
    "    # colonnes numériques continues\n",
    "\n",
    "cont_cols = []\n",
    "\n",
    "for x in df_ml:\n",
    "        if df_ml[x].nunique() > 30:\n",
    "            cont_cols.append(x)\n",
    "\n",
    "df_ml[cont_cols]=df_ml[cont_cols].fillna(df[cont_cols].median())\n",
    "print('\\nContinuous columns filled with median:\\n', cont_cols)\n",
    "\n",
    "    # colonnes catégoriques\n",
    "\n",
    "cat_cols = []\n",
    "\n",
    "for x in df_ml:\n",
    "        if df_ml[x].nunique() < 30 and df_ml[x].nunique() > 2:\n",
    "            cat_cols.append(x)\n",
    "        \n",
    "df_ml[cat_cols]=df_ml[cat_cols].fillna(df_ml[cat_cols].median())\n",
    "print('\\nCategorical columns filled with median:\\n', cat_cols)\n",
    "print('Number of columns after pre-processing:', len(bool_cols + cont_cols + cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd794e-9652-4074-b4a9-dca44119373a",
   "metadata": {},
   "source": [
    "___\n",
    "Les valeurs manquantes ont été remplacées de la manière suivante :\n",
    "+ celles des colonnes booléennes par 0 ;\n",
    "+ celles des colonnes continues par la médiane ;\n",
    "+ celles des colonnes catégoriques par la valeur médiane.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11900391-a12d-42e9-9821-4b847be2326c",
   "metadata": {},
   "source": [
    "___\n",
    "Le jeu de données a été allégé des colonnes jugées inutiles et n'en compte plus que 32, dont :\n",
    "+ 6 colonnes de type booléen ;\n",
    "+ 8 colonnes de type continu ;\n",
    "+ 18 colonnes de type catégoriel.\n",
    "\n",
    "Il est constitué entièrement de valeurs numériques. Il est donc exploitable pour le Machine Learning.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885357c1-c26e-495c-b53c-5a41353c793b",
   "metadata": {},
   "source": [
    "## 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c4b4af-891d-468b-98b7-cc60f3d0891e",
   "metadata": {},
   "source": [
    "## a) méthodologie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5df5c-0f7b-48c8-bbf9-cf84d503ca9f",
   "metadata": {},
   "source": [
    "Nous avons affaire à un problème de classification *multi-class*.\n",
    "\n",
    "La colonne *class* est la variable à prédire (target), les autres sont les *features*. On rappelle que la colonne *class* peut prendre ces valeurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81987528-5b5a-4b2e-b109-8f3a583a70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f4ac8-bc1b-4887-b848-d12cc799af96",
   "metadata": {},
   "source": [
    "Et que sa distribution est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1e45a-9986-4761-a518-2209d2a53770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].groupby(df['class']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9100a-b39c-4685-a39a-2e7fcf5efad8",
   "metadata": {},
   "source": [
    "La classe 3 est la plus représentée, la classe 4 la moins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ce6cd-9095-41d2-a1af-e6616a0d4c02",
   "metadata": {},
   "source": [
    "___\n",
    "Etant un problème de classification *multi-class*, le modèle *Random Forest* a été choisi.\n",
    "\n",
    "On va d'abord faire un premier modèle de *Random Forest* avec les valeurs par défaut nommé *Default Model*. \n",
    "\n",
    "Puis, après avoir fait des mesures de performances, paramétrer un deuxième modèle appelé *Optimized Model* afin d'améliorer les performances du premier.\n",
    "\n",
    "Enfin, on comparera les deux modèles pour voir lequel est le plus performant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce0d66-1b17-45c6-bcd2-6c58f294c336",
   "metadata": {},
   "source": [
    "### b) split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649600a-c74f-4695-9536-15353f7b05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['class']\n",
    "X = df_ml.drop(columns=['class'])\n",
    "rd_state = 2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rd_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c496b-334b-48e3-a772-31dd492c0ecc",
   "metadata": {},
   "source": [
    "### c) choix du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ffbb3-f233-47c4-8222-b14b0239c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=rd_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb9114-9fb6-4347-8fe5-3650103ab239",
   "metadata": {},
   "source": [
    "### d) mesure des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb23a46-666d-442d-8046-7689692a03b7",
   "metadata": {},
   "source": [
    "#### *- Accuracy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4b3ba-9e56-4331-a38d-1a1cfb92a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f45fc6-7fc3-497f-a642-37706ff18fa5",
   "metadata": {},
   "source": [
    "#### *- Confusion Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd0da4-3767-4624-a396-8cb820eb92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_val, y_pred)\n",
    "# print(f\"Confusion matrix:\\n{confusion}\")\n",
    "conf_norm = confusion / confusion.astype(float).sum(axis=1)\n",
    "# print(f\"Normalized confusion matrix:\\n{conf_norm}\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion).plot()\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(f'Confusion Matrix (acc: {round(accuracy, 3)})', style='italic')\n",
    "\n",
    "ConfusionMatrixDisplay(conf_norm).plot()\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(f'Normalized Confusion Matrix (acc: {round(accuracy, 3)})', style='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5564cf-a4fc-4226-8a7b-dc671d795416",
   "metadata": {},
   "source": [
    "Notons que l'apprentissage du modèle a modifié le nom des différentes classes respectivement :\n",
    "    \n",
    "    (1, 2, 3, 4, 5) --> (0, 1, 2, 3, 4)\n",
    "    \n",
    "On peut observer que :\n",
    "+ Les trois premières classes sont relativement bien prédites par le modèle (leur meilleure représentation au sein du dataset l'explique certainement) ;\n",
    "+ au contraire des deux dernières (par ailleurs, les moins bien représentées)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20e93c-417f-4105-a548-edec97e5d482",
   "metadata": {},
   "source": [
    "___\n",
    "Remarquons que le score de précision est calculé de manière générale : le poids de chaque classe dans ce score est proportionnel à leur distribution dans le jeu de données.\n",
    "\n",
    "Si le poids de chaque classe est ramené à 1, on obtient un score moins élevé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac84df-1eb4-4056-9dea-0f6eb0de7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_sum = 0\n",
    "for x in range(5):\n",
    "    conf_sum = conf_sum + conf_norm[x, x]\n",
    "conf_mean = conf_sum/(x+1)\n",
    "print(f\"Précision du modèle calculée avec des poids égaux : {round(conf_mean, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e0b1f-85ca-4969-bb31-f1a1ea5b73b2",
   "metadata": {},
   "source": [
    "#### *- Cross Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9c23e-2cb2-4ae3-9530-2afaebce234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X, y, cv=10)\n",
    "sorted(cv_results.keys())\n",
    "print(cv_results['test_score'])\n",
    "\n",
    "scores = cross_validate(model, X, y, cv=4,\n",
    "                        scoring=('r2', 'accuracy'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "print(f\"\\nMoyenne du CV: {scores['test_accuracy'].mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497deab-7e9e-4525-8462-a493424b7d04",
   "metadata": {},
   "source": [
    "### e) mesure de chaque paramètre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6238b-0cca-4fe4-b5fe-616efd7dffe2",
   "metadata": {},
   "source": [
    "#### *- random state*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05dbc4f-83a5-4b87-8fbf-4f2a24befb3d",
   "metadata": {},
   "source": [
    "On fait varier le random state du splittage pour estimer la tendance à l'overfitting du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34569ff5-bfc9-4a7f-923d-e0c11389dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['class']\n",
    "X = df_ml.drop(columns=['class'])\n",
    "acc_list = []\n",
    "\n",
    "for x in range(20):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=None)\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=None)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # mesure des performances\n",
    "    \n",
    "        # accuracy\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    # print(\"Accuracy: \", accuracy)\n",
    "    acc_list.append(accuracy)\n",
    "    \n",
    "        # plot\n",
    "\n",
    "plt.figure(1)\n",
    "plt.ylim(0.4,1)\n",
    "plt.xlim(0,20)\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(f\"Accuracy Through {len(acc_list)} Random Batches\", style=\"italic\")\n",
    "plt.xlabel(\"Batch n°\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.text(12, 0.55, f\"Accuracy mean: {round(sum(acc_list)/len(acc_list), 2)}\", style=\"italic\")\n",
    "plt.plot(acc_list, marker=\"o\", linewidth=0.5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f836b-c543-4822-aa30-6b89c7f90ed1",
   "metadata": {},
   "source": [
    "La précision du modèle varie entre 0.65 et 0.8 selon que le dataset est shufflisé avant d'être splitté. Cette variation n'est pas négligeable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2187a81-498e-40a1-a2f1-38bc2f398901",
   "metadata": {},
   "source": [
    "### *- n_estimators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3b2ec-d527-4ccd-8001-5807013839fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.arange(1,150, step=2)\n",
    "train_estimator_results = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rd_state)\n",
    "    rf = RandomForestClassifier(n_estimators=estimator, random_state=rd_state, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    train_estimator_results.append(accuracy)\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.plot(n_estimators, train_estimator_results)\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.4, 1)\n",
    "plt.grid(True)\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(\"Accuracy vs. Number of Trees\", style=\"italic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a474b4c-66de-411e-b9ca-4869e72a820d",
   "metadata": {},
   "source": [
    "Le nombre idéal d'arbres atteint un plafond aux alentours de 70 arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f89bfd-69b1-402d-8fc3-efa4b3f06b02",
   "metadata": {},
   "source": [
    "#### *- max_depth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd9c8e-abce-4235-96c1-2fc6c8800448",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(1, 30, step=1)\n",
    "train_depth_results = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rd_state)\n",
    "    model = RandomForestClassifier(n_estimators=70, max_depth=depth, random_state=rd_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    train_depth_results.append(accuracy)\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(max_depths, train_depth_results)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.4, 1)\n",
    "plt.grid(True)\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(\"Accuracy against Depth of the trees\", style=\"italic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af78843-b2a8-4c64-8f6b-e86bad190ac3",
   "metadata": {},
   "source": [
    "La précision du modèle atteint un plafond lorsque la profondeur des arbres atteint 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57b1f0-3814-45a9-be60-18d92ab9f1a5",
   "metadata": {},
   "source": [
    "#### *- train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c810212-0096-41c4-b71d-9e60fb9f2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['class']\n",
    "X = df_ml.drop(columns=['class'])\n",
    "train_test_size_results = []\n",
    "\n",
    "test_sizes = np.arange(0.01, 1, 0.02)\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rd_state, test_size=test_size)\n",
    "    model = RandomForestClassifier(max_depth=15, random_state=rd_state, n_estimators=70)\n",
    "    model.fit(X_train, y_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    train_test_size_results.append(accuracy)\n",
    "    \n",
    "plt.figure(4)\n",
    "plt.plot(test_sizes, train_test_size_results)\n",
    "plt.xlabel('Test Size Ratio')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.4, 1)\n",
    "plt.grid(True)\n",
    "plt.suptitle(\"Default Model\", fontweight='bold')\n",
    "plt.title(\"Accuracy against Test/train ratio\", style=\"italic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19927ae5-62f3-485f-b2b9-e564da9d4bda",
   "metadata": {},
   "source": [
    "Consacrer environ 30% des données au jeu de test est le ratio qui assure la meilleure précision du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d091af0-8a02-4c10-be0e-8ea96e47afb9",
   "metadata": {},
   "source": [
    "### f) optimisation des paramètres du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305dcfab-246b-4b5e-b0c6-2a6f02d4ce22",
   "metadata": {},
   "source": [
    "Maintenant que nous avons les valeurs optimales de chaque paramètre du modèle, nous pouvons les remplacer pour générer le nouveau modèle *Optimized Model*, puis nous le comparerons avec le *Default Model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93072b-9d48-4349-8c65-2cd92500488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ml['class']\n",
    "X = df_ml.drop(columns=['class'])\n",
    "optim_acc_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e27ef0-bbdd-4bbf-b473-36810d3a03a7",
   "metadata": {},
   "source": [
    "#### *- mesure des performances*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816941ce-da47-4dee-9867-70106d75ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=None, test_size=0.3)\n",
    "    \n",
    "    optimized_model = RandomForestClassifier(random_state=rd_state, n_estimators = 70, max_depth=15)\n",
    "    optimized_model.fit(X_train, y_train)    \n",
    "\n",
    "    y_pred = optimized_model.predict(X_val)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    # print(\"Accuracy: \", accuracy)\n",
    "    optim_acc_list.append(accuracy)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.ylim(0.4,1)\n",
    "plt.xlim(0,20)\n",
    "plt.suptitle(\"Optimized Model\", fontweight='bold')\n",
    "plt.title(f\"Accuracy Through {len(acc_list)} Random Batches\", style=\"italic\")\n",
    "plt.xlabel(\"Batch n°\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid(True)\n",
    "plt.text(7.3, 0.47, f\"Optimized Accuracy Mean: {round(sum(optim_acc_list)/len(optim_acc_list), 2)}\\n\\nDefault Accuracy Mean: {round(sum(acc_list)/len(acc_list), 2)}\", style=\"italic\")\n",
    "plt.plot(optim_acc_list, marker=\"o\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70d0e0-b37b-4c32-a51b-cf8ea92acec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rd_state)\n",
    "\n",
    "optimized_model = RandomForestClassifier(random_state=rd_state, n_estimators = 35, max_depth=15)\n",
    "optimized_model.fit(X_train, y_train)\n",
    "y_pred = optimized_model.predict(X_val)\n",
    "accuracy = metrics.accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f35110-d00b-4a2a-aced-d336ce76406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_val, y_pred)\n",
    "# print(f\"Confusion matrix:\\n{confusion}\")\n",
    "conf_norm = confusion / confusion.astype(float).sum(axis=1)\n",
    "#print(f\"Normalized confusion matrix:\\n{conf_norm}\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion).plot()\n",
    "plt.suptitle(\"Optimized Model\", fontweight='bold')\n",
    "plt.title(f'Confusion Matrix (acc: {round(accuracy, 3)})', style=\"italic\")\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay(conf_norm).plot()\n",
    "plt.suptitle(\"Optimized Model\", fontweight='bold')\n",
    "plt.title(f'Normalized Confusion Matrix (acc: {round(accuracy, 3)})', style=\"italic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f159c7-041b-4840-bc24-5a3cd0da1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_sum = 0\n",
    "for x in range(5):\n",
    "    conf_sum = conf_sum + conf_norm[x, x]\n",
    "conf_mean = conf_sum/(x+1)\n",
    "print(f\"Précision du modèle calculée avec des poids égaux : {round(conf_mean, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b231dc6-6308-4140-a9f1-47a6bb5c1dad",
   "metadata": {},
   "source": [
    "### g) conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4b7e6-ff7f-4e09-90c6-527ab52eb197",
   "metadata": {},
   "source": [
    "Premièrement, la précision de l'*Optimized Model* (0.69) n'est pas plus élevée que celle du *Default Model* (0.70). L'*Optimized Model* ne dépasse pas le plafond de 0.7 de précision déjà atteint par le *Default Model*. Cela peut être expliqué par le fait que les paramètres par défaut du modèle étaient très proches des paramètres optimaux.\n",
    "\n",
    "En revanche, lorsque le poids de chaque classe est égalisé, l'*Optimized Model* obtient un meilleur score de précision que celui du *Default Model*, 0.64 contre 0.58. Cela indique que les prédictions du modèle sont mieux réparties. Il répond donc mieux à l'algorithme multiclasse recherché et est plus apte à la prédiction de nouvelles données, tandis que le *Default Model* était compétent seulement pour les classes les mieux représentées.\n",
    "\n",
    "Deuxièmement, la précision atteinte par le modèle est à prendre avec précaution. Le score est étonnament élevée (~0.7) malgré le nombre restreint de données. Le risque d'overfitting de l'algorithme ne doit pas être écarté.\n",
    "\n",
    "De plus, malgré le fait que le test de Cross Validation et les shuffling effectués au split (*random_state=None*) indiquent des valeurs qui varient de +-0.1 autour de 0.7, j'ai mesuré des variations plus importantes dans les paramètres en faisant varier le random_state du modèle. Un plus grand jeu de données nous permettrait de savoir si la relative stabilité du modèle est réelle ou seulement apparente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a834e04-a3dd-4197-8327-921f77b786e3",
   "metadata": {},
   "source": [
    "## 4. Propositions d'améliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201650a-8bb9-40b0-8189-3e46cc62d20e",
   "metadata": {},
   "source": [
    "### a) au niveau du pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdeca97-d133-4049-ae39-2a119ccef7b1",
   "metadata": {},
   "source": [
    "+ essayer le *one-hot encoding* pour certaines variables catégoriques ;\n",
    "+ l'ordre des bases ACGT de la colonne *build_variant_id* sont peut-être de l'information utile à extraire ;\n",
    "+ être plus restrictif quant au choix des *features* pour diminuer le bruit afin de faciliter la tâche de l'algorithme ;\n",
    "+ chercher davantage de relations entre les features et les quantifier pour l'algorithme (*mutual information* par exemple)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a170d-9c1e-45ac-940b-9ed122ed5448",
   "metadata": {},
   "source": [
    "### b) au niveau du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602cea0-aea9-4405-a64d-e681f6cef479",
   "metadata": {},
   "source": [
    "+ essayer d'autres modèles : combiner plusieurs SGD avec une stratégie *One-vs-All* pour chaque classe. Cela permettrait d'avoir plus de contrôle sur le comportement de l'algorithme, et d'effectuer un travail de précision pour éviter la confusion entre deux classes précises ;\n",
    "+ utiliser d'autres mesures : impureté Gini, F1 score, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876efc6-7fcd-43f3-b623-91eb23f91f03",
   "metadata": {},
   "source": [
    "### c) au niveau du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50a64b-c05e-42d4-b89f-731c3d18e5ad",
   "metadata": {},
   "source": [
    "+ un nombre de données plus conséquent ;\n",
    "+ une meilleure connaissance-métier des différentes colonnes ;\n",
    "+ vérifier l'état des capteurs pour les colonnes majoritairement constituées de valeurs NaN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
